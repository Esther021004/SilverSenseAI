# main.py
from fastapi import FastAPI, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from starlette.staticfiles import StaticFiles
from starlette.responses import HTMLResponse, FileResponse
from pydantic import BaseModel
from typing import Dict
import os
import uuid

from modules.module_a_speech import analyze_speech
from modules.module_b_sound import analyze_sound, analyze_sound_from_file
from modules.module_c_fusion import fuse_situation

# ì˜ìƒ â†’ ì˜¤ë””ì˜¤ ì¶”ì¶œì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    # moviepy 2.xëŠ” video.ioì—ì„œ VideoFileClipì„ import
    from moviepy.video.io.VideoFileClip import VideoFileClip
    MOVIEPY_AVAILABLE = True
except ImportError:
    try:
        # moviepy 1.x í˜¸í™˜ì„± (êµ¬ë²„ì „)
        from moviepy.editor import VideoFileClip
        MOVIEPY_AVAILABLE = True
    except ImportError:
        MOVIEPY_AVAILABLE = False
        # ì„œë²„ ì‹œì‘ ì‹œì—ë§Œ ê²½ê³  ì¶œë ¥ (ë§¤ë²ˆ ì¶œë ¥í•˜ì§€ ì•Šë„ë¡)
        import sys
        if sys.argv[0].endswith('uvicorn') or 'main.py' in sys.argv[0]:
            print("âš ï¸  moviepyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì˜ìƒ ë¶„ì„ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì„¤ì¹˜í•˜ì„¸ìš”: pip install moviepy")


app = FastAPI(title="Emergency Assistant (Local MVP)")

# CORS ì„¤ì • (ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ API í˜¸ì¶œ í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ê°œë°œ í™˜ê²½ì—ì„œëŠ” ëª¨ë“  origin í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],  # ëª¨ë“  HTTP ë©”ì„œë“œ í—ˆìš©
    allow_headers=["*"],  # ëª¨ë“  í—¤ë” í—ˆìš©
)

# ì„ì‹œ íŒŒì¼ ì €ì¥ í´ë”
TEMP_DIR = "temp_media"
os.makedirs(TEMP_DIR, exist_ok=True)


# ==========================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==========================================
def extract_audio_from_video(video_path: str) -> str:
    """
    mp4 ë“± ì˜ìƒ íŒŒì¼ì—ì„œ ì˜¤ë””ì˜¤ íŠ¸ë™ë§Œ ì¶”ì¶œí•˜ì—¬ WAV íŒŒì¼ë¡œ ì €ì¥.
    
    Input: ì˜ìƒ íŒŒì¼ ê²½ë¡œ
    Output: ì¶”ì¶œëœ ì˜¤ë””ì˜¤ WAV íŒŒì¼ ê²½ë¡œ
    """
    if not MOVIEPY_AVAILABLE:
        raise ImportError("moviepyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install moviepy")
    
    audio_path = os.path.join(TEMP_DIR, f"{uuid.uuid4().hex}.wav")
    
    clip = VideoFileClip(video_path)
    # B ëª¨ë“ˆì´ ê¸°ëŒ€í•˜ëŠ” ìƒ˜í”Œë§ ë ˆì´íŠ¸(16000)ë¡œ ë§ì¶¤
    clip.audio.write_audiofile(
        audio_path,
        fps=16000,
        codec="pcm_s16le",
        verbose=False,
        logger=None,
    )
    clip.close()
    
    return audio_path


def run_stt_on_wav(wav_path: str) -> str:
    """
    ì˜¤ë””ì˜¤ íŒŒì¼ì—ì„œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (STT).
    
    Module Aì˜ Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ STT ìˆ˜í–‰.
    """
    try:
        # ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜í•˜ê³  ì •ê·œí™”
        wav_path = os.path.abspath(wav_path)
        # Windows ê²½ë¡œ êµ¬ë¶„ìë¥¼ ì •ê·œí™” (ë°±ìŠ¬ë˜ì‹œ â†’ ìŠ¬ë˜ì‹œë¡œ ë³€í™˜)
        wav_path_normalized = wav_path.replace('\\', '/')
        
        # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if not os.path.exists(wav_path):
            print(f"âŒ STT ì˜¤ë¥˜: ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ: {wav_path}")
            return "ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = os.path.getsize(wav_path)
        print(f"âœ… STT ì‹œì‘: {wav_path} (íŒŒì¼ í¬ê¸°: {file_size} bytes)")
        
        # íŒŒì¼ì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
        if file_size == 0:
            print("âŒ STT ì˜¤ë¥˜: ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return "ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        import whisper
        # Whisper ëª¨ë¸ ë¡œë“œ (small ëª¨ë¸ ì‚¬ìš©, í•„ìš”ì‹œ base/tinyë¡œ ë³€ê²½ ê°€ëŠ¥)
        print("ğŸ”„ Whisper ëª¨ë¸ ë¡œë“œ ì¤‘...")
        model = whisper.load_model("small")
        print("âœ… Whisper ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # transcribe í˜¸ì¶œ ì „ì— íŒŒì¼ ì¡´ì¬ ì¬í™•ì¸
        if not os.path.exists(wav_path):
            print(f"âŒ STT ì˜¤ë¥˜: transcribe í˜¸ì¶œ ì „ íŒŒì¼ì´ ì‚¬ë¼ì¡ŒìŠµë‹ˆë‹¤. ê²½ë¡œ: {wav_path}")
            return "ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        print(f"ğŸ”„ ìŒì„± ì¸ì‹ ì¤‘... (íŒŒì¼: {wav_path})")
        
        # Whisper transcribeëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ffmpegë¥¼ ì‚¬ìš©í•˜ëŠ”ë°, 
        # Windowsì—ì„œ ê²½ë¡œ ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—¬ëŸ¬ ë°©ë²• ì‹œë„
        result = None
        last_error = None
        
        # ë°©ë²• 1: ì›ë³¸ ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš© (Windows ë°±ìŠ¬ë˜ì‹œ)
        try:
            print(f"   ì‹œë„ 1: ì ˆëŒ€ ê²½ë¡œ (ë°±ìŠ¬ë˜ì‹œ)")
            result = model.transcribe(wav_path, language="ko")
            print(f"   âœ… ì„±ê³µ!")
        except (FileNotFoundError, OSError) as e1:
            last_error = e1
            print(f"   âŒ ì‹¤íŒ¨: {e1}")
            
            # ë°©ë²• 2: ì •ê·œí™”ëœ ê²½ë¡œ ì‚¬ìš© (ìŠ¬ë˜ì‹œ)
            try:
                print(f"   ì‹œë„ 2: ì •ê·œí™”ëœ ê²½ë¡œ (ìŠ¬ë˜ì‹œ)")
                result = model.transcribe(wav_path_normalized, language="ko")
                print(f"   âœ… ì„±ê³µ!")
            except (FileNotFoundError, OSError) as e2:
                last_error = e2
                print(f"   âŒ ì‹¤íŒ¨: {e2}")
                
                # ë°©ë²• 3: ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜ ì‹œë„
                try:
                    rel_path = os.path.relpath(wav_path)
                    print(f"   ì‹œë„ 3: ìƒëŒ€ ê²½ë¡œ")
                    result = model.transcribe(rel_path, language="ko")
                    print(f"   âœ… ì„±ê³µ!")
                except (FileNotFoundError, OSError) as e3:
                    last_error = e3
                    print(f"   âŒ ì‹¤íŒ¨: {e3}")
                    raise FileNotFoundError(f"ëª¨ë“  ê²½ë¡œ í˜•ì‹ ì‹œë„ ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {e3}")
        
        if result is None:
            raise FileNotFoundError(f"STT transcribe ì‹¤íŒ¨: {last_error}")
        
        text = result.get("text", "").strip()
        
        if not text:
            # STT ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜
            print("âš ï¸  STT ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return "ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        print(f"âœ… STT ì™„ë£Œ: {text[:50]}...")  # ì²˜ìŒ 50ìë§Œ ì¶œë ¥
        return text
    except ImportError:
        # whisperê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° ë”ë¯¸ í…ìŠ¤íŠ¸ ë°˜í™˜
        print("âš ï¸  whisperê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. STT ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´: pip install openai-whisper")
        return "í• ë¨¸ë‹ˆê°€ ê°‘ìê¸° ì“°ëŸ¬ì ¸ì„œ ìˆ¨ì„ ì•ˆ ì‰¬ì–´ìš”..."
    except FileNotFoundError as e:
        # íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
        print(f"âŒ STT ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ: {wav_path}")
        print(f"   ìƒì„¸ ì˜¤ë¥˜: {e}")
        return "ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        # ê¸°íƒ€ ì˜¤ë¥˜ ë°œìƒ ì‹œ
        print(f"âš ï¸  STT ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"   ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        import traceback
        print(f"   ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
        return "ìŒì„±ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."


class EmergencyAnalyzeRequest(BaseModel):
    stt_text: str
    sound_event: str
    sound_confidence: float


class EmergencyAnalyzeResponse(BaseModel):
    situation: Dict
    guideline: str


class EmergencyAnalyzeVideoResponse(BaseModel):
    situation: Dict
    guideline: str


class QuestionRequest(BaseModel):
    question: str
    situation: Dict  # í˜„ì¬ ìƒí™© ì •ë³´


class QuestionResponse(BaseModel):
    answer: str


# ì •ì  íŒŒì¼ ì„œë¹™ (HTML íŒŒì¼)
app.mount("/static", StaticFiles(directory="."), name="static")

@app.get("/")
def health_check():
    return {"status": "ok", "message": "Emergency backend running"}

@app.get("/app")
def serve_app():
    """HTML ì•± ì œê³µ"""
    return FileResponse("silversense_ai.html")

@app.get("/index")
def serve_index():
    """ì‹œì‘ í˜ì´ì§€ ì œê³µ"""
    return FileResponse("index.html")


@app.post("/api/emergency/analyze", response_model=EmergencyAnalyzeResponse)
def analyze_emergency(req: EmergencyAnalyzeRequest):
    """
    ì™¸ë¶€ì—ì„œ í˜¸ì¶œí•˜ëŠ” ë©”ì¸ API.
    
    Process Flow:
    1. A-Module: analyze_speech(stt_text)
    2. B-Module: analyze_sound(sound_event, confidence)
    3. C-Module: fuse_situation(speech, sound)
    4. ìƒí™© IDì— ë”°ë¼ ê°„ë‹¨í•œ ë„ì›€ë§ ìƒì„± (ì¶”í›„ Gemini Flash-Liteë¡œ ëŒ€ì²´)
    """
    # 1. A ëª¨ë“ˆ (ìŒì„± ë¶„ì„)
    speech_result = analyze_speech(req.stt_text)

    # 2. B ëª¨ë“ˆ (ì‚¬ìš´ë“œ ë¶„ì„)
    sound_result = analyze_sound(req.sound_event, req.sound_confidence)

    # 3. C ëª¨ë“ˆ (í“¨ì „) - Geminië¥¼ ì‚¬ìš©í•œ ìƒí™© ë¶„ì„
    situation = fuse_situation(
        speech=speech_result,
        sound=sound_result,
        source="realtime"
    )

    # 4. ìƒí™©ì— ë”°ë¥¸ ì•ˆë‚´ë¬¸ ìƒì„± (RAG ì‚¬ìš©)
    try:
        from services.rag_client import generate_guideline_from_situation
        guideline = generate_guideline_from_situation(situation)
    except ImportError:
        # RAGê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì•ˆë‚´ë¬¸ ì‚¬ìš©
        if situation.get("situation_id") == "S2":
            guideline = "ì§€ê¸ˆ ì¦‰ì‹œ 119ì— ì‹ ê³ í•˜ê³ , ì‹¬íì†Œìƒìˆ ì´ ê°€ëŠ¥í•œ ì‚¬ëŒì„ ì°¾ìœ¼ì„¸ìš”."
        elif situation.get("situation_id") in ["S1", "S3", "S5", "S6", "S7"]:
            guideline = "í™˜ìë¥¼ í¸ì•ˆíˆ ì•‰íˆê³  í†µì¦ì´ ì‹¬í•´ì§€ë©´ ì¦‰ì‹œ 119ì— ì‹ ê³ í•˜ì„¸ìš”."
        else:
            guideline = "ì¦ìƒì„ ê´€ì°°í•˜ê³  ì•…í™”ë˜ë©´ ë°”ë¡œ 119ì— ì‹ ê³ í•˜ì„¸ìš”."

    return EmergencyAnalyzeResponse(
        situation=situation,
        guideline=guideline,
    )


# python-multipartê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
try:
    import multipart
    MULTIPART_AVAILABLE = True
except ImportError:
    MULTIPART_AVAILABLE = False


if MULTIPART_AVAILABLE:
    @app.post("/api/emergency/analyze-video", response_model=EmergencyAnalyzeVideoResponse)
    async def analyze_emergency_video(file: UploadFile = File(...)):
        """
        ì˜ìƒ íŒŒì¼ ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ì‘ê¸‰ ìƒí™©ì„ ë¶„ì„í•˜ëŠ” API.
        
        ì§€ì› í˜•ì‹:
        - ì˜ìƒ: mp4, avi, mov ë“± (moviepyê°€ ì§€ì›í•˜ëŠ” í˜•ì‹)
        - ì˜¤ë””ì˜¤: wav, mp3 ë“± (ì§ì ‘ ì˜¤ë””ì˜¤ íŒŒì¼)
        
        Process Flow:
        1. íŒŒì¼ ì—…ë¡œë“œ ë° ì„ì‹œ ì €ì¥
        2. ì˜ìƒì¸ ê²½ìš° â†’ ì˜¤ë””ì˜¤ ì¶”ì¶œ (wavëŠ” ê±´ë„ˆëœ€)
        3. ì˜¤ë””ì˜¤ â†’ STT â†’ A ëª¨ë“ˆ (ìŒì„± ë¶„ì„)
        4. ì˜¤ë””ì˜¤ â†’ B ëª¨ë“ˆ (ì‚¬ìš´ë“œ ë¶„ì„)
        5. A+B â†’ C ëª¨ë“ˆ (í“¨ì „) â†’ ìµœì¢… situation JSON
        
        Input: mp4 ì˜ìƒ íŒŒì¼ ë˜ëŠ” wav ì˜¤ë””ì˜¤ íŒŒì¼
        Output: {
            "situation": {...},  # ìµœì¢… ìƒí™© ë¶„ì„ JSON
            "guideline": "..."    # ì‘ê¸‰ ëŒ€ì²˜ ê°€ì´ë“œë¼ì¸
        }
        """
        video_path = None
        audio_path = None
        
        try:
            # 1. ì—…ë¡œë“œëœ íŒŒì¼ì„ TEMP_DIRì— ì €ì¥
            file_id = uuid.uuid4().hex
            file_ext = os.path.splitext(file.filename)[1] or ".mp4"
            uploaded_path = os.path.join(TEMP_DIR, f"{file_id}{file_ext}")
            
            file_bytes = await file.read()
            with open(uploaded_path, "wb") as f:
                f.write(file_bytes)
            
            # 2. íŒŒì¼ í˜•ì‹ í™•ì¸ ë° ì˜¤ë””ì˜¤ ì¶”ì¶œ/ë³µì‚¬
            file_ext_lower = file_ext.lower()
            
            # ì˜¤ë””ì˜¤ íŒŒì¼ì¸ ê²½ìš° (wav, mp3 ë“±)
            if file_ext_lower in ['.wav', '.mp3', '.m4a', '.flac', '.ogg']:
                # ì˜¤ë””ì˜¤ íŒŒì¼ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                audio_path = uploaded_path
            else:
                # ì˜ìƒ íŒŒì¼ì¸ ê²½ìš° â†’ ì˜¤ë””ì˜¤ ì¶”ì¶œ
                if not MOVIEPY_AVAILABLE:
                    raise ImportError("moviepyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install moviepy")
                
                video_path = uploaded_path
                audio_path = extract_audio_from_video(video_path)
            
            # 3. ì˜¤ë””ì˜¤ë¡œ STT ìˆ˜í–‰ â†’ A ëª¨ë“ˆ
            stt_text = run_stt_on_wav(audio_path)
            speech_result = analyze_speech(stt_text)
            
            # 4. ì˜¤ë””ì˜¤ë¡œ B ëª¨ë“ˆ (AED CNN ëª¨ë¸)
            sound_full = analyze_sound_from_file(audio_path)
            
            # C ëª¨ë“ˆì´ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœë¡œ ë³€í™˜
            sound_result = {
                "event": sound_full.get("event", "ìƒí™œì†ŒìŒ"),
                "confidence": sound_full.get("confidence", 0.5),
            }
            
            # 5. C ëª¨ë“ˆ (Fusion + Gemini)
            situation = fuse_situation(
                speech=speech_result,
                sound=sound_result,
                source="realtime"
            )
            
            # 6. ìƒí™©ì— ë”°ë¥¸ ì•ˆë‚´ë¬¸ ìƒì„± (RAG ì‚¬ìš©)
            try:
                from services.rag_client import generate_guideline_from_situation
                guideline = generate_guideline_from_situation(situation)
            except ImportError:
                # RAGê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì•ˆë‚´ë¬¸ ì‚¬ìš©
                if situation.get("situation_id") == "S2":
                    guideline = "ì§€ê¸ˆ ì¦‰ì‹œ 119ì— ì‹ ê³ í•˜ê³ , ì‹¬íì†Œìƒìˆ ì´ ê°€ëŠ¥í•œ ì‚¬ëŒì„ ì°¾ìœ¼ì„¸ìš”."
                elif situation.get("situation_id") in ["S1", "S3", "S5", "S6", "S7"]:
                    guideline = "í™˜ìë¥¼ í¸ì•ˆíˆ ì•‰íˆê³  í†µì¦ì´ ì‹¬í•´ì§€ë©´ ì¦‰ì‹œ 119ì— ì‹ ê³ í•˜ì„¸ìš”."
                else:
                    guideline = "ì¦ìƒì„ ê´€ì°°í•˜ê³  ì•…í™”ë˜ë©´ ë°”ë¡œ 119ì— ì‹ ê³ í•˜ì„¸ìš”."
            
            return EmergencyAnalyzeVideoResponse(
                situation=situation,
                guideline=guideline,
            )
        
        except Exception as e:
            # ì—ëŸ¬ ë°œìƒ ì‹œ ìƒì„¸ ì •ë³´ ë°˜í™˜
            raise Exception(f"ì˜ìƒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        finally:
            # 7. ì„ì‹œ íŒŒì¼ ì •ë¦¬
            for path in [video_path, audio_path]:
                if path and os.path.exists(path):
                    try:
                        # ì›ë³¸ ì—…ë¡œë“œ íŒŒì¼ê³¼ ì¶”ì¶œëœ ì˜¤ë””ì˜¤ íŒŒì¼ ëª¨ë‘ ì‚­ì œ
                        os.remove(path)
                    except Exception:
                        pass
else:
    # python-multipartê°€ ì—†ìœ¼ë©´ ì—”ë“œí¬ì¸íŠ¸ë¥¼ ë“±ë¡í•˜ì§€ ì•ŠìŒ
    @app.post("/api/emergency/analyze-video")
    async def analyze_emergency_video_disabled():
        return {
            "error": "python-multipartê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "message": "ì˜ìƒ ì—…ë¡œë“œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”: pip install python-multipart"
        }


# ì§ˆë¬¸-ë‹µë³€ API
@app.post("/api/emergency/ask", response_model=QuestionResponse)
def ask_question(req: QuestionRequest):
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” API.
    í˜„ì¬ ìƒí™© ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë§ëŠ” ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        import google.generativeai as genai
        from dotenv import load_dotenv
        import os
        import traceback
        
        load_dotenv()
        api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
        
        if not api_key:
            print("âŒ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return QuestionResponse(
                answer="ì£„ì†¡í•©ë‹ˆë‹¤. AI ë‹µë³€ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )
        
        print(f"âœ… API í‚¤ í™•ì¸ ì™„ë£Œ (ê¸¸ì´: {len(api_key)})")
        genai.configure(api_key=api_key)
        
        # ìƒí™© ì •ë³´ ìš”ì•½
        situation = req.situation
        situation_id = situation.get("situation_id", "S0")
        emergency_level = situation.get("emergency_level", "low")
        symptoms = situation.get("symptoms", [])
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""ë‹¹ì‹ ì€ ì‘ê¸‰ ìƒí™©ì—ì„œ í˜¼ì ìˆëŠ” ë…¸ì¸ì„ ë„ì™€ì£¼ëŠ” ì¹œì ˆí•œ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.

í˜„ì¬ ìƒí™©:
- ìƒí™© ID: {situation_id}
- ê¸´ê¸‰ë„: {emergency_level}
- ì¦ìƒ: {', '.join(symptoms) if symptoms else 'ì—†ìŒ'}

ì‚¬ìš©ì ì§ˆë¬¸: {req.question}

ìœ„ ìƒí™©ì„ ê³ ë ¤í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
- ì§§ê³  ëª…í™•í•œ ë‹µë³€ (2-3ë¬¸ì¥)
- í˜¼ì ìˆëŠ” ë…¸ì¸ì´ ìŠ¤ìŠ¤ë¡œ í•  ìˆ˜ ìˆëŠ” ë°©ë²•ë§Œ ì œì‹œ
- ê±±ì •ì„ ëœì–´ì£¼ëŠ” ë”°ëœ»í•œ í†¤
- í•„ìš”ì‹œ 119 ì‹ ê³ ë¥¼ ê¶Œì¥

ë‹µë³€ë§Œ ì¶œë ¥í•˜ì„¸ìš” (ì„¤ëª… ì—†ì´):"""
        
        # ì—¬ëŸ¬ ëª¨ë¸ ì‹œë„ (í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ ëŒ€ì²´ ëª¨ë¸ ì‚¬ìš©)
        models_to_try = [
            'gemini-2.0-flash',  # ìµœì‹  ëª¨ë¸ (1ìˆœìœ„)
            'gemini-1.5-flash',  # ì•ˆì •ì ì¸ ë¬´ë£Œ ëª¨ë¸ (2ìˆœìœ„)
            'gemini-1.5-pro'     # ëŒ€ì²´ ëª¨ë¸ (3ìˆœìœ„)
        ]
        
        last_error = None
        for model_name in models_to_try:
            try:
                print(f"ğŸ”„ ëª¨ë¸ ì‹œë„: {model_name}")
                model = genai.GenerativeModel(model_name)
                response = model.generate_content(prompt)
                answer = response.text.strip()
                print(f"âœ… ë‹µë³€ ìƒì„± ì„±ê³µ: {model_name}")
                return QuestionResponse(answer=answer)
            except Exception as e:
                error_str = str(e)
                last_error = e
                print(f"âŒ ëª¨ë¸ {model_name} ì˜¤ë¥˜: {error_str[:200]}")
                
                # í• ë‹¹ëŸ‰ ì´ˆê³¼ ì˜¤ë¥˜ê°€ ì•„ë‹ˆë©´ ë‹¤ìŒ ëª¨ë¸ ì‹œë„í•˜ì§€ ì•ŠìŒ
                if '429' not in error_str and 'quota' not in error_str.lower():
                    print(f"âš ï¸  í• ë‹¹ëŸ‰ ì´ˆê³¼ê°€ ì•„ë‹Œ ì˜¤ë¥˜ë¡œ ì¤‘ë‹¨: {error_str[:100]}")
                    break
                # í• ë‹¹ëŸ‰ ì´ˆê³¼ë©´ ë‹¤ìŒ ëª¨ë¸ ì‹œë„
                print(f"âš ï¸  í• ë‹¹ëŸ‰ ì´ˆê³¼, ë‹¤ìŒ ëª¨ë¸ ì‹œë„...")
                continue
        
        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ë©”ì‹œì§€ ë°˜í™˜
        if last_error:
            error_str = str(last_error)
            print(f"âŒ ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {error_str[:300]}")
            
            if '429' in error_str or 'quota' in error_str.lower():
                return QuestionResponse(
                    answer="ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì„œë¹„ìŠ¤ ì‚¬ìš©ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                )
            elif 'API key' in error_str or 'authentication' in error_str.lower():
                return QuestionResponse(
                    answer="ì£„ì†¡í•©ë‹ˆë‹¤. API ì¸ì¦ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
                )
            elif 'network' in error_str.lower() or 'connection' in error_str.lower():
                return QuestionResponse(
                    answer="ì£„ì†¡í•©ë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
                )
            else:
                # ê°œë°œ í™˜ê²½ì—ì„œëŠ” ë” ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´ ì œê³µ
                return QuestionResponse(
                    answer=f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (ì˜¤ë¥˜: {error_str[:100]})"
                )
        else:
            return QuestionResponse(
                answer="ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        
    except Exception as e:
        error_str = str(e)
        traceback_str = traceback.format_exc()
        print(f"âŒ ì˜ˆì™¸ ë°œìƒ: {error_str}")
        print(f"ğŸ“‹ ìƒì„¸ ì˜¤ë¥˜:\n{traceback_str}")
        
        if '429' in error_str or 'quota' in error_str.lower():
            return QuestionResponse(
                answer="ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ì„œë¹„ìŠ¤ ì‚¬ìš©ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        elif 'API key' in error_str or 'authentication' in error_str.lower():
            return QuestionResponse(
                answer="ì£„ì†¡í•©ë‹ˆë‹¤. API ì¸ì¦ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
            )
        else:
            return QuestionResponse(
                answer=f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (ì˜¤ë¥˜: {error_str[:100]})"
            )

